{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a44b57c6-7436-4f45-abbd-2022e624e434",
   "metadata": {},
   "source": [
    "<span style=\"font-size:30px\">**Preprocesado de datos.**</span> \n",
    "    \n",
    "<span style=\"font-family: 'Verdana'; color: red;\"> *Bronquivoide* </span>\n",
    "\n",
    "### Vamos a realizar una serie de ejercicios que conforman el procedimiento de preprocesado de datos. Lo haremos desde el punto de vista de la teoría del aprendizaje supervisado. \n",
    "\n",
    "### Usaremos un archivo de formato CSV (Comma-Separated Values) de nombre *Datos_Preprocesado.csv*\n",
    "\n",
    "# **EJERCICIOS:**\n",
    "\n",
    "### **1) Cargar, leer y mostrar los datos del archivo (como es un arreglo de orden $10 \\times 4$ se puede visualizar completamente, en formato RENGLONES $\\times$ COLUMNAS).**\n",
    "\n",
    "### **2) Generar un arreglo, digamos $X$, que muestre los valores asociados a las entradas de las primeras tres columnas.** \n",
    "\n",
    "### Es decir, si vemos cada columna de nuestro conjunto de datos como un vector columna ($\\{\\vec{v_1},\\vec{v_2},\\vec{v_3},\\vec{v_4}\\}$); lo que haremos será tomar una matriz que concatena los primeros tres vectores columna: $X=[\\vec{v_1},\\vec{v_2},\\vec{v_3}]$\n",
    "\n",
    "### **3) Trabajando con los datos de $X$, operar los datos faltantes (NaN) de las columnas 2 y 3 sustituyéndolos por el valor del promedio asociado a cada columna.** \n",
    "\n",
    "### Nota: Como las columnas 1 y 4 tienen valores representados por datos categóricos, para este inciso tomemos únicamente las columnas 2 y 3.\n",
    "\n",
    "### **4) Codificar los datos categóricos de la primera columna de $X$. Es decir, transformar las entradas con categorías a valores numéricos.**\n",
    "\n",
    "### **5) Transformar los valores ordinales resultado de la codificación de los datos categóricos a variables *dummy*.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "86b4711e-2db2-4a67-b443-2bdf53c73354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ejercicio 1:\n",
      "\n",
      "\n",
      "Los datos del archivo CSV son: \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Age</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>France</td>\n",
       "      <td>44.0</td>\n",
       "      <td>72000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spain</td>\n",
       "      <td>27.0</td>\n",
       "      <td>48000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Germany</td>\n",
       "      <td>30.0</td>\n",
       "      <td>54000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Spain</td>\n",
       "      <td>38.0</td>\n",
       "      <td>61000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Germany</td>\n",
       "      <td>40.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>France</td>\n",
       "      <td>35.0</td>\n",
       "      <td>58000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Spain</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>France</td>\n",
       "      <td>48.0</td>\n",
       "      <td>79000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Germany</td>\n",
       "      <td>50.0</td>\n",
       "      <td>83000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>France</td>\n",
       "      <td>37.0</td>\n",
       "      <td>67000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Country   Age   Salary Purchased\n",
       "0   France  44.0  72000.0        No\n",
       "1    Spain  27.0  48000.0       Yes\n",
       "2  Germany  30.0  54000.0        No\n",
       "3    Spain  38.0  61000.0        No\n",
       "4  Germany  40.0      NaN       Yes\n",
       "5   France  35.0  58000.0       Yes\n",
       "6    Spain   NaN  52000.0        No\n",
       "7   France  48.0  79000.0       Yes\n",
       "8  Germany  50.0  83000.0        No\n",
       "9   France  37.0  67000.0       Yes"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Ejercicio 2:\n",
      "\n",
      "\n",
      "El arreglo de valores, X, es: \n",
      " \n",
      " [['France' 44.0 72000.0]\n",
      " ['Spain' 27.0 48000.0]\n",
      " ['Germany' 30.0 54000.0]\n",
      " ['Spain' 38.0 61000.0]\n",
      " ['Germany' 40.0 nan]\n",
      " ['France' 35.0 58000.0]\n",
      " ['Spain' nan 52000.0]\n",
      " ['France' 48.0 79000.0]\n",
      " ['Germany' 50.0 83000.0]\n",
      " ['France' 37.0 67000.0]]\n",
      "\n",
      "\n",
      "Ejercicio 3:\n",
      "\n",
      "\n",
      "El nuevo arreglo X con el procedimiento de valores faltantes especificado es: \n",
      " \n",
      " [['France' 44.0 72000.0]\n",
      " ['Spain' 27.0 48000.0]\n",
      " ['Germany' 30.0 54000.0]\n",
      " ['Spain' 38.0 61000.0]\n",
      " ['Germany' 40.0 63777.77777777778]\n",
      " ['France' 35.0 58000.0]\n",
      " ['Spain' 38.77777777777778 52000.0]\n",
      " ['France' 48.0 79000.0]\n",
      " ['Germany' 50.0 83000.0]\n",
      " ['France' 37.0 67000.0]]\n",
      "\n",
      "\n",
      "Ejercicio 4:\n",
      "\n",
      "\n",
      "El arreglo con los datos categóricos codificados es: \n",
      " \n",
      " [[0 44.0 72000.0]\n",
      " [2 27.0 48000.0]\n",
      " [1 30.0 54000.0]\n",
      " [2 38.0 61000.0]\n",
      " [1 40.0 63777.77777777778]\n",
      " [0 35.0 58000.0]\n",
      " [2 38.77777777777778 52000.0]\n",
      " [0 48.0 79000.0]\n",
      " [1 50.0 83000.0]\n",
      " [0 37.0 67000.0]]\n",
      "\n",
      "\n",
      "Ejercicio 5:\n",
      "\n",
      "\n",
      "El arreglo con las variables dummy es: \n",
      " \n",
      " [[1.0 0.0 0.0 44.0 72000.0]\n",
      " [0.0 0.0 1.0 27.0 48000.0]\n",
      " [0.0 1.0 0.0 30.0 54000.0]\n",
      " [0.0 0.0 1.0 38.0 61000.0]\n",
      " [0.0 1.0 0.0 40.0 63777.77777777778]\n",
      " [1.0 0.0 0.0 35.0 58000.0]\n",
      " [0.0 0.0 1.0 38.77777777777778 52000.0]\n",
      " [1.0 0.0 0.0 48.0 79000.0]\n",
      " [0.0 1.0 0.0 50.0 83000.0]\n",
      " [1.0 0.0 0.0 37.0 67000.0]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Ejercicio 1\n",
    "print(f\"Ejercicio 1:\")\n",
    "print( \"\\n\")\n",
    "#Carga y lectura de datos mediante la biblioteca Pandas:\n",
    "datos=pd.read_csv('Datos_Preprocesado.csv')\n",
    "print(f\"Los datos del archivo CSV son: \\n\")\n",
    "display(datos)\n",
    "print( \"\\n\")\n",
    "\n",
    "#Ejercicio 2\n",
    "print(f\"Ejercicio 2:\")\n",
    "print( \"\\n\")\n",
    "#Arreglo de Python (o matriz) que muestra únicamente los valores en las primeras tres columnas:\n",
    "X=datos.iloc[:,:-1].values\n",
    "print(f\"El arreglo de valores, X, es: \\n \\n {X}\")\n",
    "print( \"\\n\")\n",
    "\n",
    "#Ejercicio 3\n",
    "print(f\"Ejercicio 3:\")\n",
    "print( \"\\n\")\n",
    "#Definimos el método especificado en el ejercicio para operar los NaN:\n",
    "método=SimpleImputer(missing_values=np.nan, strategy=\"mean\")\n",
    "#Aplicamos el método únicamente sobre las columnas 2 y 3:\n",
    "ajuste=método.fit(X[:,1:3]) \n",
    "#Sobreescribir los datos con este ajuste:\n",
    "X[:,1:3]=ajuste.transform(X[:,1:3])\n",
    "#Mostrar el nuevo arreglo de datos:\n",
    "print(f\"El nuevo arreglo X con el procedimiento de valores faltantes especificado es: \\n \\n {X}\")\n",
    "print( \"\\n\")\n",
    "\n",
    "#Ejercicio 4\n",
    "print(f\"Ejercicio 4:\")\n",
    "print( \"\\n\")\n",
    "codificación=LabelEncoder() #Creamos el codificador\n",
    "X[:,0]=codificación.fit_transform(X[:,0])\n",
    "print(f\"El arreglo con los datos categóricos codificados es: \\n \\n {X}\")\n",
    "print( \"\\n\")\n",
    "\n",
    "#Ejercicio 5\n",
    "print(f\"Ejercicio 5:\")\n",
    "print( \"\\n\")\n",
    "tranformación_columnas=ColumnTransformer([('dummys', OneHotEncoder(categories='auto'), [0])], remainder='passthrough')\n",
    "X = np.array(tranformación_columnas.fit_transform(X))\n",
    "print(f\"El arreglo con las variables dummy es: \\n \\n {X}\")\n",
    "print( \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52337b51-1bc8-4cd2-af9e-e177ee2b4372",
   "metadata": {},
   "source": [
    "### Nótense las formas de los mapeos que hemos hecho en la primera columna. Primero mapeamos las entradas del vector $\\vec{v_1}$ de dimensión $10$, las cuales eran cadenas de caracteres, a valores numéricos ordinales, esto corresponde al proceso de codificación. Podemos verlo de la siguiente forma:\n",
    "\n",
    "### $ CODIFICACIÓN: CARACTERES \\rightarrow \\mathbb{R}$, mediante $CODIFICACIÓN(v_1 ^ m)=a$. En donde en este caso $a\\in \\{0,1,2\\}$ (el término $ v_1 ^ m$ hace referencia a la $m$-ésima entrada de $\\vec{v_1}$).\n",
    "\n",
    "### Luego implementamos un mapeo que podemos ver de la forma:\n",
    "\n",
    "### $ DUMMY: CARACTERES \\rightarrow \\{0,1\\}$, mediante $DUMMY(v_1 ^ m)=0,1$\n",
    "\n",
    "### Lo anterior de tal forma que la matriz $X$ de tres columnas pasó a ser de cinco columnas ($X=[\\vec{v_1},\\vec{v_2},\\vec{v_3},\\vec{v_4},\\vec{v_5}]$), pues la transformación de valores ordinales a no ordinales (dummy) resultó en una clasificación binaria de tres datos categóricos posibles (\"France\", \"Spain\" y \"Germany\")\n",
    "\n",
    "### **6) Dividir el data set en conjunto de entrenamiento y conjunto de prueba.**\n",
    "\n",
    "### Recordemos que el conjunto de entrenamiento está definido por el conjunto de pares $\\{ (\\vec{x_i}, y_i)\\}_{i=1} ^n$, en donde $\\{ \\vec{x_i}\\}$ es el conjunto de ejemplares de entrada  tal que $ \\vec{x_i} \\in \\mathbb{R}^d$ ($d$ es la dimensión del espacio de entradas), mientras que $\\{ y_i\\}$ es el conjunto de ejemplares de salida (o predicciones) tal que $y_i \\in \\mathbb{R}$.\n",
    "\n",
    "### Consideremos las salidas $y_i$ como los datos de la cuarta columna de Datos_Preprocesado.csv, así, en nuestro caso las entradas $\\vec{x_i}$ son los vectores renglones tal que $i=1,2,..,10$. La concatenación vertical de los $\\vec{x_i}$ van a conformar la matriz $X$.\n",
    "\n",
    "### De lo anterior, vamos a tener dos conjuntos de pares:\n",
    "\n",
    "<font size=\"5\">  $\\{ (\\vec{x_i}^{train}, y_i ^{train})\\}_{i=1} ^{10}$ </font>\n",
    "\n",
    "<font size=\"5\">  $\\{ (\\vec{x_i}^{test}, y_i ^{test})\\}_{i=1} ^{10}$ </font>\n",
    "\n",
    "### Nota: Para dividir el data set tendremos que considerar el vector columna $\\vec{y}$ de entradas $y_i$ y codificar también sus entradas, pues contiene datos categóricos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fabe0a96-6a82-45f0-b5f0-cad43e7f50b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ejercicio 6:\n",
      "\n",
      "\n",
      "El vector de salidas, y, es: \n",
      " \n",
      " ['No' 'Yes' 'No' 'No' 'Yes' 'Yes' 'No' 'Yes' 'No' 'Yes']\n",
      "\n",
      "\n",
      "El vector y codificado es: \n",
      " \n",
      " [0 1 0 0 1 1 0 1 0 1]\n",
      "\n",
      "\n",
      "La matriz X de entrenamiento es: \n",
      " \n",
      " [[1.0 0.0 0.0 37.0 67000.0]\n",
      " [0.0 0.0 1.0 27.0 48000.0]\n",
      " [1.0 0.0 0.0 35.0 58000.0]\n",
      " [0.0 0.0 1.0 38.0 61000.0]\n",
      " [1.0 0.0 0.0 44.0 72000.0]\n",
      " [0.0 0.0 1.0 38.77777777777778 52000.0]\n",
      " [1.0 0.0 0.0 48.0 79000.0]\n",
      " [0.0 1.0 0.0 50.0 83000.0]]\n",
      "\n",
      "\n",
      "La matriz X de prueba es: \n",
      " \n",
      " [[0.0 1.0 0.0 30.0 54000.0]\n",
      " [0.0 1.0 0.0 40.0 63777.77777777778]]\n",
      "\n",
      "\n",
      "El vector y de entrenamiento es: \n",
      " \n",
      " [1 1 1 0 0 0 1 0]\n",
      "\n",
      "\n",
      "El vector y de prueba es: \n",
      " \n",
      " [0 1]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Ejercicio 6\n",
    "print(f\"Ejercicio 6:\")\n",
    "print( \"\\n\")\n",
    "#Definimos el vector de salidas y:\n",
    "y=datos.iloc[:, 3].values\n",
    "print(f\"El vector de salidas, y, es: \\n \\n {y}\")\n",
    "print( \"\\n\")\n",
    "#Codificando las categorías:\n",
    "codificación_y=LabelEncoder()\n",
    "y=codificación_y.fit_transform(y)\n",
    "print(f\"El vector y codificado es: \\n \\n {y}\")\n",
    "print( \"\\n\")\n",
    "#División en datos de train y de test:\n",
    "X_train , X_test , y_train , y_test = train_test_split(X, y, test_size = 0.2) #El test size de 0.2 manda 20% de datos al testing.\n",
    "print(f\"La matriz X de entrenamiento es: \\n \\n {X_train}\")\n",
    "print( \"\\n\")\n",
    "print(f\"La matriz X de prueba es: \\n \\n {X_test}\")\n",
    "print( \"\\n\")\n",
    "print(f\"El vector y de entrenamiento es: \\n \\n {y_train}\")\n",
    "print( \"\\n\")\n",
    "print(f\"El vector y de prueba es: \\n \\n {y_test}\")\n",
    "print( \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73052864-6b7c-4725-af08-6b6318b13e0c",
   "metadata": {},
   "source": [
    "### 7) Realizar un escalamiento de datos al conjunto $X$ de entrenamiento y al de prueba.\n",
    "\n",
    "### Nota: La función StandardScaler() realiza una normalización (o bien, una estandarización) a cada entrada de la matriz $X$ en términos del promedio y la desviación estándar de cada columna:\n",
    "\n",
    "<font size=\"5\"> $Sc(X_{ij})=\\frac{X_{ij}-\\mu_j}{\\sigma _j}$</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a7bff783-ea27-4240-96a2-6a32f3ee7acb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ejercicio 7:\n",
      "\n",
      "\n",
      "El conjunto X de entrenamiento escalado es: \n",
      " \n",
      " [[ 1.         -0.37796447 -0.77459667  0.61435084  0.59805036]\n",
      " [ 1.         -0.37796447 -0.77459667 -0.6781795  -0.59805036]\n",
      " [-1.         -0.37796447  1.29099445 -1.82709535 -1.45240802]\n",
      " [-1.          2.64575131 -0.77459667  1.47603773  1.53784378]\n",
      " [ 1.         -0.37796447 -0.77459667  1.18880877  1.19610072]\n",
      " [-1.         -0.37796447  1.29099445 -0.1356359  -1.11066496]\n",
      " [-1.         -0.37796447  1.29099445 -0.24733605 -0.34174306]\n",
      " [ 1.         -0.37796447 -0.77459667 -0.39095053  0.17087153]]\n",
      "\n",
      "\n",
      "El conjunto X de prueba escalado es: \n",
      " \n",
      " [[-1.          2.64575131 -0.77459667 -1.39625191 -0.93979342]\n",
      " [-1.          2.64575131 -0.77459667  0.03989291 -0.10442149]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Ejercicio 7\n",
    "print(f\"Ejercicio 7:\")\n",
    "print( \"\\n\")\n",
    "#Llamamos a la función de escalamiento:\n",
    "sc_X=StandardScaler()\n",
    "#Escalamiento para X_train:\n",
    "X_train=sc_X.fit_transform(X_train)\n",
    "#Escalamiento para X_test:\n",
    "X_test=sc_X.transform(X_test)\n",
    "print(f\"El conjunto X de entrenamiento escalado es: \\n \\n {X_train}\")\n",
    "print( \"\\n\")\n",
    "print(f\"El conjunto X de prueba escalado es: \\n \\n {X_test}\")\n",
    "print( \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6942a7-edd0-4ab0-b548-5fbf125ea5f5",
   "metadata": {},
   "source": [
    "# Fin de los ejercicios."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
